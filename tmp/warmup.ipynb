{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This is a notebook for learning the codebase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, shelve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "source": [
    "## Dataset\n",
    "- Rihkye tasks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RihkyeTask():\n",
    "    def __init__(self, num_cueingcontext, num_cue, num_rule, rule, blocklen, block_cueingcontext, tsteps, cuesteps, batch_size):\n",
    "        '''Generate Rihkye task dataset\n",
    "        Parameters:\n",
    "            num_cueingcontext: int, number of cueing contexts\n",
    "            num_cue: int, number of cues in each cueing contexts\n",
    "            num_rule: int, number of rules (e.g. attend to audition is a rule)\n",
    "            rule: list of int, rule corresponding to one cue in one cueing context\n",
    "            blocklen: list of int, trainlen of each block\n",
    "            block_cueingcontext: list of int, cueing context trained in each block\n",
    "            tsteps: int, length of a trial, equals to cuesteps + delaystep\n",
    "            cuesteps: int, length of showing cues\n",
    "            batch_size: int\n",
    "        '''\n",
    "        self.num_cueingcontext = num_cueingcontext\n",
    "        self.num_cue = num_cue\n",
    "        self.num_rule = num_rule\n",
    "        self.rule = rule\n",
    "\n",
    "        self.blockrange = np.zeros_like(blocklen) # index range of each block\n",
    "        for i in range(len(blocklen)):\n",
    "            self.blockrange[i] = sum(blocklen[:i+1])\n",
    "\n",
    "        self.block_cueingcontext = block_cueingcontext\n",
    "        self.tsteps = tsteps\n",
    "        self.cuesteps = cuesteps\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Initialize counter\n",
    "        self.traini = 0\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Return the input stimulus and target output for one cycle.\n",
    "        Parameters:\n",
    "            No parameter\n",
    "\n",
    "        Returns:\n",
    "            input: (n_time, n_input)\n",
    "            target: (n_time, n_output)\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = np.zeros((self.tsteps * self.num_cue, self.batch_size, self.num_cue*self.num_cueingcontext))\n",
    "        targets = np.zeros((self.tsteps * self.num_cue, self.batch_size, self.num_rule))\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            blocki = np.argwhere(self.traini / self.blockrange < 1.0)\n",
    "            if len(blocki) == 0:\n",
    "                raise ValueError(\"the end\")\n",
    "            blocki = int(blocki[0])\n",
    "            cueingcontext = self.block_cueingcontext[blocki]\n",
    "\n",
    "            cueList = self.get_cue_list(cueingcontext)\n",
    "\n",
    "            cues_order = np.random.permutation(cueList)\n",
    "\n",
    "\n",
    "            t_start = 0\n",
    "            for cueingcontext, cuei in cues_order:\n",
    "                cue, target = self.get_cue_target(cueingcontext, cuei)\n",
    "                inputs[t_start:t_start+self.cuesteps, i, :] = cue\n",
    "                targets[t_start:t_start+self.tsteps, i, :] = target\n",
    "                t_start += self.tsteps\n",
    "\n",
    "            self.traini += 1\n",
    "\n",
    "        return inputs, targets\n",
    "\n",
    "    # Helper functions\n",
    "    def get_cue_list(self, cueingcontext):\n",
    "        '''\n",
    "        Return:\n",
    "        (cueingcontext, cuei) combinations for one training step\n",
    "        '''\n",
    "        cueList = np.dstack(( np.repeat(cueingcontext,self.num_cue), \n",
    "                                np.arange(self.num_cue) ))\n",
    "\n",
    "        return cueList[0]\n",
    "\n",
    "    def get_cue_target(self, cueingcontext, cuei):\n",
    "        cue = np.zeros(self.num_cue*self.num_cueingcontext)\n",
    "        cue[cueingcontext*self.num_cue + cuei] = 1.\n",
    "\n",
    "        target = np.zeros(self.num_rule)\n",
    "        target[self.rule[cueingcontext*self.num_cue + cuei]] = 1\n",
    "\n",
    "        return cue, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(400, 10, 4) (400, 10, 2) \n\n"
     ]
    }
   ],
   "source": [
    "RNGSEED = 5\n",
    "np.random.seed([RNGSEED])\n",
    "\n",
    "num_cueingcontext = 2\n",
    "num_cue = 2\n",
    "num_rule = 2\n",
    "rule = [0, 1, 0, 1]\n",
    "blocklen = [500, 500, 200]\n",
    "block_cueingcontext = [0, 1, 0]\n",
    "tsteps = 200\n",
    "cuesteps = 100\n",
    "batch_size = 10\n",
    "\n",
    "dataset = RihkyeTask(num_cueingcontext=num_cueingcontext, num_cue=num_cue, num_rule=num_rule, rule=rule, blocklen=blocklen, block_cueingcontext=block_cueingcontext, tsteps=tsteps, cuesteps=cuesteps, batch_size=batch_size)\n",
    "\n",
    "input, target = dataset()\n",
    "print(input.shape, target.shape, '\\n')\n",
    "#print(input)\n",
    "#print(target)"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensoryInputLayer():\n",
    "    def __init__(self, n_sub, n_cues, n_output):\n",
    "        # TODO: Hard-coded for now\n",
    "        self.Ncues = n_cues\n",
    "        self.Nsub = n_sub\n",
    "        self.Nneur = n_output\n",
    "        self.positiveRates = True\n",
    "\n",
    "        self.wIn = np.zeros((self.Nneur, self.Ncues))\n",
    "        self.cueFactor = 1.5\n",
    "        if self.positiveRates:\n",
    "            lowcue, highcue = 0.5, 1.\n",
    "        else:\n",
    "            lowcue, highcue = -1., 1\n",
    "        for cuei in np.arange(self.Ncues):\n",
    "            self.wIn[self.Nsub * cuei:self.Nsub * (cuei + 1), cuei] = \\\n",
    "                np.random.uniform(lowcue, highcue, size=self.Nsub) * self.cueFactor\n",
    "\n",
    "        self._use_torch = False\n",
    "\n",
    "    def __call__(self, input):\n",
    "        if self._use_torch:\n",
    "            input = input.numpy()\n",
    "\n",
    "        output = np.dot(self.wIn, input)\n",
    "\n",
    "        if self._use_torch:\n",
    "            output = torch.from_numpy(output).astype(torch.float)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def torch(self, use_torch=True):\n",
    "        self._use_torch = use_torch\n",
    "\n",
    "\n",
    "class PFC():\n",
    "    def __init__(self, n_neuron, n_neuron_per_cue, positiveRates=True, MDeffect=True):\n",
    "        self.Nneur = n_neuron\n",
    "        self.Nsub = n_neuron_per_cue\n",
    "        self.useMult = True\n",
    "        self.noisePresent = False\n",
    "        self.noiseSD = 1e-3#1e-3\n",
    "        self.tau = 0.02\n",
    "        self.dt = 0.001\n",
    "                    \n",
    "        self.positiveRates = positiveRates\n",
    "        if self.positiveRates:\n",
    "            # only +ve rates\n",
    "            self.activation = lambda inp: np.clip(np.tanh(inp), 0, None)\n",
    "        else:\n",
    "            # both +ve/-ve rates as in Miconi\n",
    "            self.activation = lambda inp: np.tanh(inp)\n",
    "\n",
    "        self.G = 0.75  # determines also the cross-task recurrence\n",
    "        # With MDeffect = True and MDstrength = 0, i.e. MD inactivated\n",
    "        #  PFC recurrence is (1+PFC_G_off)*Gbase = (1+1.5)*0.75 = 1.875\n",
    "        # So with MDeffect = False, ensure the same PFC recurrence for the pure reservoir\n",
    "        if not MDeffect: self.G = 1.875\n",
    "\n",
    "        self.init_activity()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_activity(self):\n",
    "        self.xinp = np.random.uniform(0, 0.1, size=(self.Nneur))\n",
    "        self.activity = self.activation(self.xinp)\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.Jrec = np.random.normal(size=(self.Nneur, self.Nneur)) * self.G / np.sqrt(self.Nsub * 2)\n",
    "        # make mean input to each row zero,\n",
    "        #  helps to avoid saturation (both sides) for positive-only rates.\n",
    "        #  see Nicola & Clopath 2016\n",
    "        self.Jrec -= np.mean(self.Jrec, axis=1)[:, np.newaxis]\n",
    "        # mean of rows i.e. across columns (axis 1),\n",
    "        #  then expand with np.newaxis\n",
    "        #   so that numpy's broadcast works on rows not columns\n",
    "\n",
    "    def __call__(self, input, input_x=None, *args, **kwargs):\n",
    "        \"\"\"Run the network one step\n",
    "\n",
    "        For now, consider this network receiving input from PFC,\n",
    "        input stands for activity of PFC neurons\n",
    "        output stands for output current to PFC neurons\n",
    "\n",
    "        Args:\n",
    "            input: array (n_neuron,)\n",
    "            input_x: array (n_neuron,), modulatory input that multiplicatively\n",
    "                interact with the neurons\n",
    "\n",
    "        Returns:\n",
    "            output: array (n_output,)\n",
    "        \"\"\"\n",
    "\n",
    "        if input_x is None:\n",
    "            input_x = np.zeros_like(input)\n",
    "            \n",
    "        xadd = np.dot(self.Jrec, self.activity)\n",
    "        xadd += input_x + input # MD inputs\n",
    "        \n",
    "        self.xinp += self.dt / self.tau * (-self.xinp + xadd)\n",
    "\n",
    "        if self.noisePresent:\n",
    "            self.xinp += np.random.normal(size=(self.Nneur)) * self.noiseSD * np.sqrt(self.dt) / self.tau\n",
    "\n",
    "        rout = self.activation(self.xinp)\n",
    "        self.activity = rout\n",
    "        return rout\n",
    "\n",
    "    def update_weights(self, input, activity, output):\n",
    "        self.trace = self.trace + activity\n",
    "        w_input = self.w_input + input * self.trace\n",
    "        w_output = self.w_output + input * self.trace\n",
    "\n",
    "\n",
    "class MD():\n",
    "    def __init__(self, Nneur, Num_MD, num_active=1, positiveRates=True, dt=0.001):\n",
    "        self.Nneur = Nneur\n",
    "        self.Num_MD = Num_MD\n",
    "        self.positiveRates = positiveRates\n",
    "        self.num_active = num_active # num_active: num MD active per context\n",
    "\n",
    "        self.tau = 0.02\n",
    "        self.tau_times = 4\n",
    "        self.dt = dt\n",
    "        self.tsteps = 200\n",
    "        self.Hebb_learning_rate = 1e-4\n",
    "        Gbase = 0.75  # determines also the cross-task recurrence\n",
    "\n",
    "        self.wPFC2MD = np.random.normal(0, 1 / np.sqrt(self.Num_MD * self.Nneur)    , size=(self.Num_MD, self.Nneur))\n",
    "        self.wMD2PFC = np.random.normal(0, 1 / np.sqrt(self.Num_MD * self.Nneur)    , size=(self.Nneur, self.Num_MD))\n",
    "        self.wMD2PFCMult = np.random.normal(0, 1 / np.sqrt(self.Num_MD * self.Nneur), size=(self.Nneur, self.Num_MD))\n",
    "        self.MDpreTrace = np.zeros(shape=(self.Nneur))\n",
    "        self.MDpostTrace = np.zeros(shape=(self.Num_MD))\n",
    "        self.MDpreTrace_threshold = 0\n",
    "\n",
    "        # Choose G based on the type of activation function\n",
    "        # unclipped activation requires lower G than clipped activation,\n",
    "        #  which in turn requires lower G than shifted tanh activation.\n",
    "        if self.positiveRates:\n",
    "            self.G = Gbase\n",
    "            self.tauMD = self.tau * self.tau_times  ##self.tau\n",
    "        else:\n",
    "            self.G = Gbase\n",
    "            self.MDthreshold = 0.4\n",
    "            self.tauMD = self.tau * 10 * self.tau_times\n",
    "        self.init_activity()\n",
    "        \n",
    "    def init_activity(self):\n",
    "        self.MDinp = np.zeros(shape=self.Num_MD)\n",
    "        \n",
    "    def __call__(self, input, *args, **kwargs):\n",
    "        \"\"\"Run the network one step\n",
    "\n",
    "        For now, consider this network receiving input from PFC,\n",
    "        input stands for activity of PFC neurons\n",
    "        output stands for output current to MD neurons\n",
    "\n",
    "        Args:\n",
    "            input: array (n_input,)\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "            output: array (n_output,)\n",
    "        \"\"\"\n",
    "        # MD decays 10x slower than PFC neurons,\n",
    "        #  so as to somewhat integrate PFC input\n",
    "        if self.positiveRates:\n",
    "            self.MDinp += (self.dt / self.tauMD) * (-self.MDinp + np.dot(self.wPFC2MD, input))\n",
    "        else:  # shift PFC rates, so that mean is non-zero to turn MD on\n",
    "            self.MDinp += (self.dt / self.tauMD) * (-self.MDinp + np.dot(self.wPFC2MD, (input + 1. / 2)))\n",
    "                     \n",
    "        MDout = self.winner_take_all(self.MDinp)\n",
    "\n",
    "        self.update_weights(input, MDout)\n",
    "\n",
    "        return MDout\n",
    "\n",
    "    def update_trace(self, rout, MDout):\n",
    "        # MD presynaptic traces filtered over 10 trials\n",
    "        # Ideally one should weight them with MD syn weights,\n",
    "        #  but syn plasticity just uses pre!\n",
    "        self.MDpreTrace += 1. / self.tsteps / 5. * (-self.MDpreTrace + rout)\n",
    "        self.MDpostTrace += 1. / self.tsteps / 5. * (-self.MDpostTrace + MDout)\n",
    "        # MDoutTrace =  self.MDpostTrace\n",
    "\n",
    "        MDoutTrace = self.winner_take_all(self.MDpostTrace)\n",
    "\n",
    "        return MDoutTrace\n",
    "\n",
    "    def update_weights(self, rout, MDout):\n",
    "        \"\"\"Update weights with plasticity rules.\n",
    "\n",
    "        Args:\n",
    "            rout: input to MD\n",
    "            MDout: activity of MD\n",
    "        \"\"\"\n",
    "        MDoutTrace = self.update_trace(rout, MDout)\n",
    "        #                    if self.MDpostTrace[0] > self.MDpostTrace[1]: MDoutTrace = np.array([1,0])\n",
    "        #                    else: MDoutTrace = np.array([0,1])\n",
    "        self.MDpreTrace_threshold = np.mean(self.MDpreTrace)\n",
    "        #self.MDpreTrace_threshold = np.mean(self.MDpreTrace[:self.Nsub * self.Ncues])  # first 800 cells are cue selective\n",
    "        # MDoutTrace_threshold = np.mean(MDoutTrace) #median\n",
    "        MDoutTrace_threshold = 0.5  \n",
    "        wPFC2MDdelta = 0.5 * self.Hebb_learning_rate * np.outer(MDoutTrace - MDoutTrace_threshold,self.MDpreTrace - self.MDpreTrace_threshold)\n",
    "\n",
    "        # Update and clip the weights\n",
    "        self.wPFC2MD = np.clip(self.wPFC2MD + wPFC2MDdelta, 0., 1.)\n",
    "        self.wMD2PFC = np.clip(self.wMD2PFC + 0.1 * (wPFC2MDdelta.T), -10., 0.)\n",
    "        self.wMD2PFCMult = np.clip(self.wMD2PFCMult + 0.1 * (wPFC2MDdelta.T), 0.,7. / self.G)\n",
    "\n",
    "    def winner_take_all(self, MDinp):\n",
    "        '''Winner take all on the MD\n",
    "        '''\n",
    "\n",
    "        # Thresholding\n",
    "        MDout = np.zeros(self.Num_MD)\n",
    "        MDinp_sorted = np.sort(MDinp)\n",
    "        # num_active = np.round(self.Num_MD / self.Ntasks)\n",
    "\n",
    "        MDthreshold = np.mean(MDinp_sorted[-int(self.num_active) * 2:])\n",
    "        # MDthreshold  = np.mean(MDinp)\n",
    "        index_pos = np.where(MDinp >= MDthreshold)\n",
    "        index_neg = np.where(MDinp < MDthreshold)\n",
    "        MDout[index_pos] = 1\n",
    "        MDout[index_neg] = 0\n",
    "\n",
    "        return MDout\n",
    "\n",
    "\n",
    "class OutputLayer():\n",
    "    def __init__(self, n_input, n_out, dt):\n",
    "        self.dt = dt\n",
    "        self.tau = 0.02\n",
    "        self.tauError = 0.001\n",
    "        self.Nout = n_out\n",
    "        self.Nneur = n_input\n",
    "        self.learning_rate = 5e-6\n",
    "        self.wOut = np.random.uniform(-1, 1,\n",
    "                                      size=(\n",
    "                                      self.Nout, self.Nneur)) / self.Nneur\n",
    "        self.state = np.zeros(shape=self.Nout)\n",
    "        self.error_smooth = np.zeros(shape=self.Nout)\n",
    "        self.activation = lambda inp: np.clip(np.tanh(inp), 0, None)\n",
    "\n",
    "    def __call__(self, input, target, *args, **kwargs):\n",
    "        outAdd = np.dot(self.wOut, input)\n",
    "        self.state += self.dt / self.tau * (-self.state + outAdd)\n",
    "        output = self.activation(self.state)\n",
    "        self.update_weights(input, output, target)\n",
    "        return output\n",
    "\n",
    "    def update_weights(self, input, output, target):\n",
    "        \"\"\"error-driven i.e. error*pre (perceptron like) learning\"\"\"\n",
    "        error = output - target\n",
    "        self.error_smooth += self.dt / self.tauError * (-self.error_smooth + error)\n",
    "        self.wOut += -self.learning_rate * np.outer(self.error_smooth, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNetwork():\n",
    "    def __init__(self, Num_PFC, n_neuron_per_cue, Num_MD, num_active, MDeffect=True):\n",
    "        dt = 0.001\n",
    "        self.sensory2pfc = SensoryInputLayer(n_sub=n_neuron_per_cue, n_cues=4, n_output=Num_PFC)\n",
    "        self.pfc = PFC(Num_PFC, n_neuron_per_cue, MDeffect=MDeffect)\n",
    "        self.pfc2out = OutputLayer(n_input=Num_PFC, n_out=2, dt=dt)\n",
    "        self.pfc_output_t = np.array([])\n",
    "        \n",
    "        self.MDeffect = MDeffect\n",
    "        if self.MDeffect:\n",
    "            self.md = MD(Nneur=Num_PFC, Num_MD=Num_MD, num_active=num_active, dt=dt)\n",
    "\n",
    "            self.md_output = np.zeros(Num_MD)\n",
    "            index = np.random.permutation(Num_MD)\n",
    "            self.md_output[index[:num_active]] = 1 # randomly set num_active indices of md_output to 1\n",
    "            self.md_output_t = np.array([])\n",
    "\n",
    "    def __call__(self, input, target, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "             input: (n_time, n_input)\n",
    "             target: (n_time, n_output)\n",
    "             \n",
    "        \"\"\"\n",
    "        self._check_shape(input, target)\n",
    "        n_time = input.shape[0]\n",
    "        tsteps = 200\n",
    "\n",
    "        self.pfc.init_activity()  # Reinit PFC activity\n",
    "        pfc_output = self.pfc.activity\n",
    "        if self.MDeffect:\n",
    "            self.md.init_activity()  # Reinit MD activity\n",
    "\n",
    "        output = np.zeros((n_time, target.shape[-1]))\n",
    "        self.pfc_output_t *= 0\n",
    "        if self.MDeffect:\n",
    "            self.md_output_t *= 0\n",
    "\n",
    "        for i in range(n_time):\n",
    "            input_t = input[i]\n",
    "            target_t = target[i]\n",
    "            \n",
    "            if i % tsteps == 0: # Reinit activity for each trial\n",
    "                self.pfc.init_activity()  # Reinit PFC activity\n",
    "                pfc_output = self.pfc.activity\n",
    "                if self.MDeffect:\n",
    "                    self.md.init_activity()  # Reinit MD activity\n",
    "\n",
    "            input2pfc = self.sensory2pfc(input_t)\n",
    "            if self.MDeffect:\n",
    "                self.md_output = self.md(pfc_output)\n",
    "\n",
    "                self.md.MD2PFCMult = np.dot(self.md.wMD2PFCMult, self.md_output)\n",
    "                rec_inp = np.dot(self.pfc.Jrec, self.pfc.activity)\n",
    "                md2pfc_weights = (self.md.MD2PFCMult / np.round(self.md.Num_MD / 2))\n",
    "                md2pfc = md2pfc_weights * rec_inp  \n",
    "                md2pfc += np.dot(self.md.wMD2PFC / np.round(self.md.Num_MD /2), self.md_output) \n",
    "                pfc_output = self.pfc(input2pfc, md2pfc)\n",
    "\n",
    "                if i==0:\n",
    "                    self.pfc_output_t = pfc_output.reshape((1,pfc_output.shape[0]))\n",
    "                    self.md_output_t = self.md_output.reshape((1,self.md_output.shape[0]))\n",
    "                else:\n",
    "                    self.pfc_output_t = np.concatenate((self.pfc_output_t, pfc_output.reshape((1,pfc_output.shape[0]))),axis=0)\n",
    "                    self.md_output_t = np.concatenate((self.md_output_t, self.md_output.reshape((1,self.md_output.shape[0]))),axis=0)\n",
    "            \n",
    "            else:\n",
    "                pfc_output = self.pfc(input2pfc)\n",
    "                if i==0:\n",
    "                    self.pfc_output_t = pfc_output.reshape((1,pfc_output.shape[0]))\n",
    "                else:\n",
    "                    self.pfc_output_t = np.concatenate((self.pfc_output_t, pfc_output.reshape((1,pfc_output.shape[0]))),axis=0)\n",
    "            output[i] = self.pfc2out(pfc_output, target_t)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _check_shape(self, input, target):\n",
    "        assert len(input.shape) == 2\n",
    "        assert len(target.shape) == 2\n",
    "        assert input.shape[0] == target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchPFC(nn.Module):\n",
    "    def __init__(self, n_neuron, n_neuron_per_cue, positiveRates=True):\n",
    "        super().__init__()\n",
    "        self.Nneur = n_neuron\n",
    "        self.Nsub = n_neuron_per_cue\n",
    "        self.useMult = True\n",
    "        self.noisePresent = False\n",
    "        self.noiseSD = 1e-1  # 1e-3\n",
    "        self.tau = 0.02\n",
    "        self.dt = 0.001\n",
    "\n",
    "        self.positiveRates = positiveRates\n",
    "        if self.positiveRates:\n",
    "            # only +ve rates\n",
    "            self.activation = lambda inp: torch.clip(torch.tanh(inp), 0, None)\n",
    "        else:\n",
    "            # both +ve/-ve rates as in Miconi\n",
    "            self.activation = lambda inp: torch.tanh(inp)\n",
    "\n",
    "        self.G = 0.75  # determines also the cross-task recurrence\n",
    "\n",
    "        self.init_activity()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_activity(self):\n",
    "        self.xinp = torch.rand(self.Nneur) * 0.1\n",
    "        self.activity = self.activation(self.xinp)\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.Jrec = torch.normal(mean=0, std=self.G / np.sqrt(self.Nsub * 2)*2, size=(self.Nneur, self.Nneur))\n",
    "        # make mean input to each row zero,\n",
    "        #  helps to avoid saturation (both sides) for positive-only rates.\n",
    "        #  see Nicola & Clopath 2016\n",
    "        # mean of rows i.e. across columns (axis 1),\n",
    "        #  then expand with np.newaxis\n",
    "        #   so that numpy's broadcast works on rows not columns\n",
    "        self.Jrec -= torch.mean(self.Jrec, dim=1).unsqueeze_(dim=1)\n",
    "\n",
    "    def forward(self, input, input_x=None):\n",
    "        \"\"\"Run the network one step\n",
    "\n",
    "        For now, consider this network receiving input from PFC,\n",
    "        input stand for activity of PFC neurons\n",
    "        output stand for output current to PFC neurons\n",
    "\n",
    "        Args:\n",
    "            input: array (n_neuron,)\n",
    "            input_x: array (n_neuron,), modulatory input that multiplicatively interact with the neurons\n",
    "\n",
    "        Returns:\n",
    "            output: array (n_output,)\n",
    "        \"\"\"\n",
    "        if input_x is None:\n",
    "            input_x = torch.zeros(input.shape)\n",
    "\n",
    "        xadd = torch.matmul(self.Jrec, self.activity)\n",
    "        xadd += input_x + input  # MD inputs\n",
    "        self.xinp += self.dt / self.tau * (-self.xinp + xadd)\n",
    "        rout = self.activation(self.xinp)\n",
    "        self.activity = rout\n",
    "        return rout"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNGSEED = 5 # set random seed\n",
    "np.random.seed([RNGSEED])\n",
    "\n",
    "Ntrain = 500            # number of training cycles for each context\n",
    "Nextra = 200            # add cycles to show if block1\n",
    "Ncontexts = 2           # number of cueing contexts (e.g. auditory cueing context)\n",
    "inpsPerConext = 2       # in a cueing context, there are <inpsPerConext> kinds of stimuli\n",
    "                         # (e.g. auditory cueing context contains high-pass noise and low-pass noise)\n",
    "\n",
    "# generate trainset\n",
    "dataset = RihkyeTask(Ntrain=Ntrain, Nextra=Nextra, Ncontexts=Ncontexts, inpsPerConext=inpsPerConext, blockTrain=True)\n",
    "\n",
    "# model parameters\n",
    "n_neuron = 1000\n",
    "n_neuron_per_cue = 200\n",
    "Num_MD = 10\n",
    "num_active = 5  # num MD active per context\n",
    "n_output = 2\n",
    "MDeffect = True\n",
    "\n",
    "model = FullNetwork(n_neuron, n_neuron_per_cue, Num_MD, num_active, MDeffect=MDeffect)"
   ]
  },
  {
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "log = defaultdict(list)\n",
    "\n",
    "num_cycle_train = Ntrain*Ncontexts+Nextra\n",
    "mses = list()\n",
    "MDpreTraces = np.zeros(shape=(num_cycle_train,n_neuron))\n",
    "MDouts_all = np.zeros(shape=(num_cycle_train,Num_MD))\n",
    "PFCouts_all = np.zeros(shape=(num_cycle_train,n_neuron))\n",
    "\n",
    "for i in tqdm(range(num_cycle_train)):\n",
    "    input, target = dataset()\n",
    "    output = model(input, target)\n",
    "    mse = np.mean((output - target)**2)*Ncontexts # one cycle has Ncontexts\n",
    "\n",
    "#    mse = np.mean((output[:200] - target[:200])**2)\n",
    "#    mse += np.mean((output[200:] - target[200:])**2)\n",
    "    PFCouts_all[i,:] = model.pfc.activity\n",
    "    log['mse'].append(mse)\n",
    "    if  MDeffect == True:\n",
    "        MDouts_all[i,:] = model.md_output\n",
    "        MDpreTraces[i,:] = model.md.MDpreTrace\n",
    "\n",
    "# write MD weights\n",
    "if  MDeffect == True:  \n",
    "    log['wPFC2MD'] = model.md.wPFC2MD\n",
    "    log['wMD2PFC'] = model.md.wMD2PFC\n",
    "    log['wMD2PFCMult'] = model.md.wMD2PFCMult\n",
    "\n",
    "# write model\n",
    "filename = Path('files')\n",
    "os.makedirs(filename, exist_ok=True)\n",
    "file_training = 'train_numMD'+str(Num_MD)+'_numContext'+str(Ncontexts)+'_MD'+str(MDeffect)+'_R'+str(RNGSEED)+'.pkl'\n",
    "with open(filename / file_training, 'wb') as f:\n",
    "    pickle.dump(log, f)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}