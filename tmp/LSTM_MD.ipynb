{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RihkyeTask + LSTM_MD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from task import RihkyeTask\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from temp_model import MD, LSTM_MD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cueingcontext = 2\n",
    "num_cue = 2\n",
    "num_rule = 2\n",
    "rule = [0, 1, 0, 1]\n",
    "blocklen = [500, 500, 200]\n",
    "block_cueingcontext = [0, 1, 0]\n",
    "tsteps = 200\n",
    "cuesteps = 100\n",
    "batch_size = 1 # always set to 1 right now\n",
    "\n",
    "dataset = RihkyeTask(num_cueingcontext=num_cueingcontext, num_cue=num_cue, num_rule=num_rule, rule=rule, blocklen=blocklen, \\\n",
    "block_cueingcontext=block_cueingcontext, tsteps=tsteps, cuesteps=cuesteps, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total step: 1200\n",
      "Training sample index: 0-10\n",
      "loss: 0.35947\n",
      "Predicted left training time: 455 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 10-20\n",
      "loss: 0.20197\n",
      "Predicted left training time: 340 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 20-30\n",
      "loss: 0.11952\n",
      "Predicted left training time: 339 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 30-40\n",
      "loss: 0.05078\n",
      "Predicted left training time: 293 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 40-50\n",
      "loss: 0.03651\n",
      "Predicted left training time: 353 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 50-60\n",
      "loss: 0.02727\n",
      "Predicted left training time: 393 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 60-70\n",
      "loss: 0.02678\n",
      "Predicted left training time: 284 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 70-80\n",
      "loss: 0.02392\n",
      "Predicted left training time: 282 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 80-90\n",
      "loss: 0.02053\n",
      "Predicted left training time: 284 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 90-100\n",
      "loss: 0.01986\n",
      "Predicted left training time: 282 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 100-110\n",
      "loss: 0.01930\n",
      "Predicted left training time: 273 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 110-120\n",
      "loss: 0.01772\n",
      "Predicted left training time: 279 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 120-130\n",
      "loss: 0.01625\n",
      "Predicted left training time: 277 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 130-140\n",
      "loss: 0.01613\n",
      "Predicted left training time: 262 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 140-150\n",
      "loss: 0.01599\n",
      "Predicted left training time: 261 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 150-160\n",
      "loss: 0.01349\n",
      "Predicted left training time: 263 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 160-170\n",
      "loss: 0.01215\n",
      "Predicted left training time: 253 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 170-180\n",
      "loss: 0.01170\n",
      "Predicted left training time: 248 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 180-190\n",
      "loss: 0.01110\n",
      "Predicted left training time: 248 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 190-200\n",
      "loss: 0.01019\n",
      "Predicted left training time: 259 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 200-210\n",
      "loss: 0.00927\n",
      "Predicted left training time: 275 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 210-220\n",
      "loss: 0.00857\n",
      "Predicted left training time: 261 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 220-230\n",
      "loss: 0.00807\n",
      "Predicted left training time: 237 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 230-240\n",
      "loss: 0.00790\n",
      "Predicted left training time: 248 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 240-250\n",
      "loss: 0.00740\n",
      "Predicted left training time: 233 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 250-260\n",
      "loss: 0.00722\n",
      "Predicted left training time: 240 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 260-270\n",
      "loss: 0.00662\n",
      "Predicted left training time: 237 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 270-280\n",
      "loss: 0.00649\n",
      "Predicted left training time: 236 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 280-290\n",
      "loss: 0.00602\n",
      "Predicted left training time: 229 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 290-300\n",
      "loss: 0.00567\n",
      "Predicted left training time: 228 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 300-310\n",
      "loss: 0.00544\n",
      "Predicted left training time: 226 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 310-320\n",
      "loss: 0.00521\n",
      "Predicted left training time: 226 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 320-330\n",
      "loss: 0.00514\n",
      "Predicted left training time: 214 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 330-340\n",
      "loss: 0.00505\n",
      "Predicted left training time: 215 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 340-350\n",
      "loss: 0.00488\n",
      "Predicted left training time: 216 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 350-360\n",
      "loss: 0.00458\n",
      "Predicted left training time: 217 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 360-370\n",
      "loss: 0.00433\n",
      "Predicted left training time: 220 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 370-380\n",
      "loss: 0.00417\n",
      "Predicted left training time: 211 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 380-390\n",
      "loss: 0.00386\n",
      "Predicted left training time: 202 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 390-400\n",
      "loss: 0.00385\n",
      "Predicted left training time: 204 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 400-410\n",
      "loss: 0.00381\n",
      "Predicted left training time: 195 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 410-420\n",
      "loss: 0.00354\n",
      "Predicted left training time: 194 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 420-430\n",
      "loss: 0.00329\n",
      "Predicted left training time: 195 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 430-440\n",
      "loss: 0.00337\n",
      "Predicted left training time: 188 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 440-450\n",
      "loss: 0.00325\n",
      "Predicted left training time: 188 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 450-460\n",
      "loss: 0.00312\n",
      "Predicted left training time: 196 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 460-470\n",
      "loss: 0.00300\n",
      "Predicted left training time: 190 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 470-480\n",
      "loss: 0.00296\n",
      "Predicted left training time: 184 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 480-490\n",
      "loss: 0.00289\n",
      "Predicted left training time: 168 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 490-500\n",
      "loss: 0.00284\n",
      "Predicted left training time: 174 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 500-510\n",
      "loss: 0.23962\n",
      "Predicted left training time: 171 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 510-520\n",
      "loss: 0.06565\n",
      "Predicted left training time: 182 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 520-530\n",
      "loss: 0.02737\n",
      "Predicted left training time: 171 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 530-540\n",
      "loss: 0.02239\n",
      "Predicted left training time: 167 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 540-550\n",
      "loss: 0.01236\n",
      "Predicted left training time: 164 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 550-560\n",
      "loss: 0.00909\n",
      "Predicted left training time: 161 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 560-570\n",
      "loss: 0.00808\n",
      "Predicted left training time: 159 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 570-580\n",
      "loss: 0.00721\n",
      "Predicted left training time: 161 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 580-590\n",
      "loss: 0.00681\n",
      "Predicted left training time: 153 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 590-600\n",
      "loss: 0.00619\n",
      "Predicted left training time: 148 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 600-610\n",
      "loss: 0.00588\n",
      "Predicted left training time: 146 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 610-620\n",
      "loss: 0.00578\n",
      "Predicted left training time: 143 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 620-630\n",
      "loss: 0.00541\n",
      "Predicted left training time: 141 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 630-640\n",
      "loss: 0.00513\n",
      "Predicted left training time: 139 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 640-650\n",
      "loss: 0.00501\n",
      "Predicted left training time: 147 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 650-660\n",
      "loss: 0.00469\n",
      "Predicted left training time: 132 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 660-670\n",
      "loss: 0.00466\n",
      "Predicted left training time: 133 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 670-680\n",
      "loss: 0.00443\n",
      "Predicted left training time: 135 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 680-690\n",
      "loss: 0.00442\n",
      "Predicted left training time: 132 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 690-700\n",
      "loss: 0.00411\n",
      "Predicted left training time: 127 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 700-710\n",
      "loss: 0.00412\n",
      "Predicted left training time: 123 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 710-720\n",
      "loss: 0.00409\n",
      "Predicted left training time: 122 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 720-730\n",
      "loss: 0.00385\n",
      "Predicted left training time: 123 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 730-740\n",
      "loss: 0.00368\n",
      "Predicted left training time: 115 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 740-750\n",
      "loss: 0.00348\n",
      "Predicted left training time: 109 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 750-760\n",
      "loss: 0.00350\n",
      "Predicted left training time: 106 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 760-770\n",
      "loss: 0.00347\n",
      "Predicted left training time: 104 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 770-780\n",
      "loss: 0.00334\n",
      "Predicted left training time: 103 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 780-790\n",
      "loss: 0.00337\n",
      "Predicted left training time: 101 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 790-800\n",
      "loss: 0.00322\n",
      "Predicted left training time: 103 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 800-810\n",
      "loss: 0.00321\n",
      "Predicted left training time: 107 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 810-820\n",
      "loss: 0.00310\n",
      "Predicted left training time: 95 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 820-830\n",
      "loss: 0.00304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted left training time: 90 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 830-840\n",
      "loss: 0.00292\n",
      "Predicted left training time: 94 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 840-850\n",
      "loss: 0.00289\n",
      "Predicted left training time: 88 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 850-860\n",
      "loss: 0.00274\n",
      "Predicted left training time: 85 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 860-870\n",
      "loss: 0.00272\n",
      "Predicted left training time: 87 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 870-880\n",
      "loss: 0.00267\n",
      "Predicted left training time: 81 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 880-890\n",
      "loss: 0.00261\n",
      "Predicted left training time: 77 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 890-900\n",
      "loss: 0.00253\n",
      "Predicted left training time: 78 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 900-910\n",
      "loss: 0.00246\n",
      "Predicted left training time: 75 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 910-920\n",
      "loss: 0.00247\n",
      "Predicted left training time: 72 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 920-930\n",
      "loss: 0.00240\n",
      "Predicted left training time: 71 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 930-940\n",
      "loss: 0.00233\n",
      "Predicted left training time: 65 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 940-950\n",
      "loss: 0.00224\n",
      "Predicted left training time: 62 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 950-960\n",
      "loss: 0.00221\n",
      "Predicted left training time: 62 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 960-970\n",
      "loss: 0.00216\n",
      "Predicted left training time: 59 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 970-980\n",
      "loss: 0.00206\n",
      "Predicted left training time: 59 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 980-990\n",
      "loss: 0.00201\n",
      "Predicted left training time: 55 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 990-1000\n",
      "loss: 0.00205\n",
      "Predicted left training time: 49 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1000-1010\n",
      "loss: 0.00312\n",
      "Predicted left training time: 49 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1010-1020\n",
      "loss: 0.00246\n",
      "Predicted left training time: 47 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1020-1030\n",
      "loss: 0.00227\n",
      "Predicted left training time: 43 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1030-1040\n",
      "loss: 0.00207\n",
      "Predicted left training time: 40 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1040-1050\n",
      "loss: 0.00185\n",
      "Predicted left training time: 38 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1050-1060\n",
      "loss: 0.00172\n",
      "Predicted left training time: 38 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1060-1070\n",
      "loss: 0.00165\n",
      "Predicted left training time: 33 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1070-1080\n",
      "loss: 0.00161\n",
      "Predicted left training time: 31 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1080-1090\n",
      "loss: 0.00155\n",
      "Predicted left training time: 28 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1090-1100\n",
      "loss: 0.00150\n",
      "Predicted left training time: 26 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1100-1110\n",
      "loss: 0.00147\n",
      "Predicted left training time: 23 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1110-1120\n",
      "loss: 0.00144\n",
      "Predicted left training time: 21 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1120-1130\n",
      "loss: 0.00139\n",
      "Predicted left training time: 18 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1130-1140\n",
      "loss: 0.00139\n",
      "Predicted left training time: 15 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1140-1150\n",
      "loss: 0.00135\n",
      "Predicted left training time: 12 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1150-1160\n",
      "loss: 0.00130\n",
      "Predicted left training time: 10 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1160-1170\n",
      "loss: 0.00128\n",
      "Predicted left training time: 7 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1170-1180\n",
      "loss: 0.00125\n",
      "Predicted left training time: 5 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1180-1190\n",
      "loss: 0.00122\n",
      "Predicted left training time: 3 s\n",
      "\n",
      "Total step: 1200\n",
      "Training sample index: 1190-1200\n",
      "loss: 0.00119\n",
      "Predicted left training time: 0 s\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Model settings\n",
    "input_size = 4 # 4 cues\n",
    "hidden_size = 200\n",
    "output_size = 2 # 2 rules\n",
    "num_layers = 1\n",
    "Num_MD = 10\n",
    "num_active = 5\n",
    "tsteps = 200\n",
    "\n",
    "model = LSTM_MD(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers, Num_MD=Num_MD, \\\n",
    "    num_active=num_active, tsteps=tsteps)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "total_step = sum(blocklen)//batch_size\n",
    "print_step = 10\n",
    "running_loss = 0.0\n",
    "running_train_time = 0\n",
    "losses = []\n",
    "timestamps = []\n",
    "model_name = 'model-' + str(int(time.time()))\n",
    "savemodel = False\n",
    "\n",
    "\n",
    "for i in range(total_step):\n",
    "\n",
    "    train_time_start = time.time()\n",
    "\n",
    "    # extract data\n",
    "    inputs, labels = dataset()\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float)\n",
    "    labels = torch.from_numpy(labels).type(torch.float)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs, labels)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # normalization\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_train_time += time.time() - train_time_start\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if i % print_step == (print_step - 1):\n",
    "        print('Total step: {:d}'.format(total_step))\n",
    "        print('Training sample index: {:d}-{:d}'.format(i+1-print_step, i+1))\n",
    "\n",
    "        # running loss\n",
    "        print('loss: {:0.5f}'.format(running_loss / print_step))\n",
    "        losses.append(running_loss / print_step)\n",
    "        timestamps.append(i+1-print_step)\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # training time\n",
    "        print('Predicted left training time: {:0.0f} s'.format(\n",
    "        (running_train_time) * (total_step - i - 1) / print_step),\n",
    "        end='\\n\\n')\n",
    "        running_train_time = 0\n",
    "\n",
    "        if savemodel:\n",
    "            # save model every print_step\n",
    "            fname = os.path.join('models', model_name + '.pt')\n",
    "            torch.save(model.state_dict(), fname)\n",
    "\n",
    "            # save info of the model\n",
    "            fpath = os.path.join('models', model_name + '.txt')\n",
    "            with open(fpath, 'w') as f:\n",
    "                f.write('input_size = ' + str(input_size) + '\\n')\n",
    "                f.write('hidden_size = ' + str(hidden_size) + '\\n')\n",
    "                f.write('output_size = ' + str(output_size) + '\\n')\n",
    "                f.write('num_layers = ' + str(num_layers) + '\\n')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(timestamps, losses, label='Without MD')\n",
    "plt.xlabel('Cycles')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.legend()\n",
    "plt.xticks([0, 500, 1000, 1200])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# deprecated\n",
    "#lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1, proj_size=2)\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1)\n",
    "input = torch.randn(5, 3, 10)\n",
    "#h0 = torch.randn(1, 3, 20)\n",
    "#c0 = torch.randn(1, 3, 20)\n",
    "output, _= lstm(input)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
